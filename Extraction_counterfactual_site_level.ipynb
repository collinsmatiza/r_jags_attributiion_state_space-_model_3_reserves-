{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330fe804-70df-4ae6-9289-b1298c510b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import rasterio as rio\n",
    "import geopandas as gpd\n",
    "import rasterstats as rstats\n",
    "import rioxarray\n",
    "from rasterio.enums import Resampling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Imported packages\")\n",
    "\n",
    "# Load shapefile\n",
    "shp_fo = r'/Users/collinsmatiza/Documents/Analysis/protected_sites_with_srtm_elevation.shp'\n",
    "print(f\"Loading shapefile: {shp_fo}\")\n",
    "\n",
    "try:\n",
    "    shp_df = gpd.read_file(shp_fo)\n",
    "    print(\"Shapefile loaded\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading shapefile: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Filter for specific protected areas\n",
    "target_areas = ['Garden Route National Park', 'Mphaphuli Protected Environment']\n",
    "print(f\"Filtering for target areas: {target_areas}\")\n",
    "\n",
    "# Filter the shapefile using correct column name\n",
    "filtered_shp = shp_df[shp_df['CUR_NME'].isin(target_areas)].copy()\n",
    "\n",
    "if len(filtered_shp) == 0:\n",
    "    print(\"No matching protected areas found. Please check the area names and column name.\")\n",
    "    print(\"Available area names (first 10):\", shp_df['CUR_NME'].head(10).tolist())\n",
    "    exit(1)\n",
    "else:\n",
    "    print(f\"Found {len(filtered_shp)} matching protected areas\")\n",
    "\n",
    "# Convert shapefile to WGS84 if it's not already\n",
    "print(f\"Original shapefile CRS: {shp_df.crs}\")\n",
    "if shp_df.crs != 'EPSG:4326':\n",
    "    print(\"Converting shapefile to WGS84 (EPSG:4326)...\")\n",
    "    filtered_shp = filtered_shp.to_crs('EPSG:4326')\n",
    "    print(\"Conversion complete\")\n",
    "\n",
    "# Check if protected areas are in the data extent\n",
    "print(\"\\nChecking protected area locations (WGS84 coordinates):\")\n",
    "for _, row in filtered_shp.iterrows():\n",
    "    bounds = row.geometry.bounds\n",
    "    print(f\"{row['CUR_NME']}: lon {bounds[0]:.4f} to {bounds[2]:.4f}, lat {bounds[1]:.4f} to {bounds[3]:.4f}\")\n",
    "\n",
    "# Data extent from diagnostic: lon 16.25 to 32.75, lat -35.75 to -22.25\n",
    "data_lon_range = (16.25, 32.75)\n",
    "data_lat_range = (-35.75, -22.25)\n",
    "print(f\"Data extent: lon {data_lon_range[0]} to {data_lon_range[1]}, lat {data_lat_range[0]} to {data_lat_range[1]}\")\n",
    "\n",
    "# Define target resolution\n",
    "TARGET_RESOLUTION = 0.025  # degrees\n",
    "print(f\"Target pixel resolution: {TARGET_RESOLUTION} degrees\")\n",
    "\n",
    "# Base path for NetCDF files\n",
    "base_path = '/Users/collinsmatiza/Downloads/isimip3a/counterclim/20crv3/mon/'\n",
    "\n",
    "# Find all precipitation files in the directory\n",
    "pr_files = glob.glob(os.path.join(base_path, 'pr_mon_*.nc'))\n",
    "if not pr_files:\n",
    "    pr_files = glob.glob(os.path.join(base_path, 'pr_*mon*.nc'))\n",
    "    if not pr_files:\n",
    "        print(f\"No precipitation files found in: {base_path}\")\n",
    "        exit(1)\n",
    "\n",
    "# Find all temperature files in the directory\n",
    "tas_files = glob.glob(os.path.join(base_path, 'tas_mon_*.nc'))\n",
    "if not tas_files:\n",
    "    tas_files = glob.glob(os.path.join(base_path, 'tas_*mon*.nc'))\n",
    "    if not tas_files:\n",
    "        print(f\"No temperature files found in: {base_path}\")\n",
    "        exit(1)\n",
    "\n",
    "print(f\"Found {len(pr_files)} precipitation files\")\n",
    "print(f\"Found {len(tas_files)} temperature files\")\n",
    "pr_files.sort()\n",
    "tas_files.sort()\n",
    "\n",
    "# Initialize list to store all pixel data\n",
    "# Create dictionaries to match precipitation and temperature files by year\n",
    "pr_files_by_year = {}\n",
    "tas_files_by_year = {}\n",
    "\n",
    "def extract_year_from_filename(filename):\n",
    "    \"\"\"Extract year from filename\"\"\"\n",
    "    basename = os.path.basename(filename)\n",
    "    if '_' in basename:\n",
    "        parts = basename.split('_')\n",
    "        for part in parts:\n",
    "            clean_part = part.replace('.nc', '')\n",
    "            if clean_part.isdigit() and len(clean_part) == 4:\n",
    "                return int(clean_part)\n",
    "    return None\n",
    "\n",
    "# Group files by year\n",
    "for pr_file in pr_files:\n",
    "    year = extract_year_from_filename(pr_file)\n",
    "    if year and 1982 <= year <= 2015:\n",
    "        pr_files_by_year[year] = pr_file\n",
    "\n",
    "for tas_file in tas_files:\n",
    "    year = extract_year_from_filename(tas_file)\n",
    "    if year and 1982 <= year <= 2015:\n",
    "        tas_files_by_year[year] = tas_file\n",
    "\n",
    "# Find common years\n",
    "common_years = set(pr_files_by_year.keys()) & set(tas_files_by_year.keys())\n",
    "print(f\"Common years with both precipitation and temperature data: {len(common_years)}\")\n",
    "print(f\"Years: {sorted(common_years)}\")\n",
    "\n",
    "if not common_years:\n",
    "    print(\"No matching years found between precipitation and temperature files!\")\n",
    "    exit(1)\n",
    "\n",
    "# Conversion factors dictionary - your data is in kg m-2 s-1, convert to mm/month\n",
    "conversion_factors = {\n",
    "    'kg m-2 s-1': 86400 * 30.44,  # Convert to mm/month (avg days per month)\n",
    "    'kg/mÂ²/s': 86400 * 30.44,\n",
    "    'kg/m2/s': 86400 * 30.44,\n",
    "    'm s-1': 86400000 * 30.44,\n",
    "    'm/s': 86400000 * 30.44,\n",
    "    'mm s-1': 86400 * 30.44,\n",
    "    'mm/s': 86400 * 30.44,\n",
    "    'mm/day': 30.44,  # Convert daily to monthly\n",
    "    'mm day-1': 30.44,\n",
    "    'mm/month': 1\n",
    "}\n",
    "\n",
    "def resample_to_target_resolution(data_array, original_transform, target_resolution):\n",
    "    \"\"\"\n",
    "    Resample data array to target resolution using bilinear interpolation\n",
    "    \"\"\"\n",
    "    from rasterio.warp import reproject, Resampling as RioResampling\n",
    "    from rasterio.transform import from_bounds\n",
    "    \n",
    "    # Get original bounds\n",
    "    height, width = data_array.shape\n",
    "    west, north = original_transform * (0, 0)\n",
    "    east, south = original_transform * (width, height)\n",
    "    \n",
    "    # Calculate new dimensions\n",
    "    new_width = int(np.ceil((east - west) / target_resolution))\n",
    "    new_height = int(np.ceil((north - south) / target_resolution))\n",
    "    \n",
    "    # Create new transform\n",
    "    new_transform = from_bounds(west, south, east, north, new_width, new_height)\n",
    "    \n",
    "    # Create destination array\n",
    "    dst_array = np.empty((new_height, new_width), dtype=data_array.dtype)\n",
    "    dst_array[:] = np.nan\n",
    "    \n",
    "    # Reproject\n",
    "    reproject(\n",
    "        data_array,\n",
    "        dst_array,\n",
    "        src_transform=original_transform,\n",
    "        dst_transform=new_transform,\n",
    "        src_crs='EPSG:4326',\n",
    "        dst_crs='EPSG:4326',\n",
    "        resampling=RioResampling.bilinear\n",
    "    )\n",
    "    \n",
    "    return dst_array, new_transform\n",
    "\n",
    "def process_climate_data(file_path, var_name, conversion_factor=1, target_units=''):\n",
    "    \"\"\"Process climate data file and return resampled data for each time step\"\"\"\n",
    "    ds = None\n",
    "    try:\n",
    "        ds = xr.open_dataset(file_path)\n",
    "        data_var = ds[var_name]\n",
    "        \n",
    "        # Get units and apply conversion\n",
    "        units = data_var.attrs.get('units', '')\n",
    "        print(f\"    Original {var_name} units: {units}\")\n",
    "        \n",
    "        # Set up spatial coordinates\n",
    "        if 'longitude' in data_var.dims:\n",
    "            data_var = data_var.rename({'longitude': 'x', 'latitude': 'y'})\n",
    "        \n",
    "        # Set CRS explicitly\n",
    "        data_var = data_var.rio.write_crs(\"EPSG:4326\")\n",
    "        \n",
    "        # Create original transform\n",
    "        lon_res = float(data_var.x[1] - data_var.x[0])\n",
    "        lat_res = float(data_var.y[1] - data_var.y[0])\n",
    "        \n",
    "        from rasterio.transform import from_bounds\n",
    "        west, south, east, north = float(data_var.x.min()), float(data_var.y.min()), float(data_var.x.max()), float(data_var.y.max())\n",
    "        \n",
    "        # Adjust bounds to pixel edges\n",
    "        west -= lon_res / 2\n",
    "        east += lon_res / 2\n",
    "        south -= abs(lat_res) / 2\n",
    "        north += abs(lat_res) / 2\n",
    "        \n",
    "        original_affine = from_bounds(west, south, east, north, len(data_var.x), len(data_var.y))\n",
    "        \n",
    "        # Process each time step\n",
    "        time_data_dict = {}\n",
    "        for time_idx in range(len(data_var.time)):\n",
    "            time_val = data_var.time[time_idx].values\n",
    "            date_obj = pd.to_datetime(time_val)\n",
    "            date_str = date_obj.strftime('%Y-%m-%d')\n",
    "            \n",
    "            # Select data for this time step\n",
    "            time_data = data_var.isel(time=time_idx)\n",
    "            \n",
    "            # Apply conversion\n",
    "            if var_name == 'pr':\n",
    "                time_data = time_data * conversion_factor\n",
    "            elif var_name == 'tas':\n",
    "                time_data = time_data + conversion_factor\n",
    "            \n",
    "            # Extract values and flip if necessary\n",
    "            data_array = time_data.values\n",
    "            \n",
    "            # Check if y-coordinates are decreasing\n",
    "            if len(data_var.y) > 1 and data_var.y[0] > data_var.y[1]:\n",
    "                data_array = np.flipud(data_array)\n",
    "            \n",
    "            # Skip if all NaN\n",
    "            if np.all(np.isnan(data_array)):\n",
    "                continue\n",
    "            \n",
    "            # Resample to target resolution\n",
    "            resampled_array, resampled_affine = resample_to_target_resolution(\n",
    "                data_array, original_affine, TARGET_RESOLUTION\n",
    "            )\n",
    "            \n",
    "            time_data_dict[date_str] = {\n",
    "                'data': resampled_array,\n",
    "                'affine': resampled_affine\n",
    "            }\n",
    "        \n",
    "        return time_data_dict, target_units\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    Error processing {var_name} data: {e}\")\n",
    "        return {}, ''\n",
    "    finally:\n",
    "        if ds is not None:\n",
    "            ds.close()\n",
    "\n",
    "all_pixel_data = []\n",
    "pixel_counter = 0  # Global pixel counter for sequential IDs\n",
    "pixel_id_map = {}  # Dictionary to map (lon, lat) to unique pixel IDs\n",
    "\n",
    "# Process each year\n",
    "for year in sorted(common_years):\n",
    "    pr_file = pr_files_by_year[year]\n",
    "    tas_file = tas_files_by_year[year]\n",
    "    \n",
    "    print(f\"\\nProcessing year {year}:\")\n",
    "    print(f\"  Precipitation file: {os.path.basename(pr_file)}\")\n",
    "    print(f\"  Temperature file: {os.path.basename(tas_file)}\")\n",
    "    \n",
    "    # Process precipitation data\n",
    "    print(\"  Processing precipitation...\")\n",
    "    pr_data_dict, pr_units = process_climate_data(pr_file, 'pr', \n",
    "                                                  conversion_factors.get('kg m-2 s-1', 86400 * 30.44), \n",
    "                                                  'mm/month')\n",
    "    \n",
    "    # Process temperature data  \n",
    "    print(\"  Processing temperature...\")\n",
    "    # Temperature is typically in Kelvin, convert to Celsius by subtracting 273.15\n",
    "    tas_data_dict, tas_units = process_climate_data(tas_file, 'tas', -273.15, 'Celsius')\n",
    "    \n",
    "    if not pr_data_dict or not tas_data_dict:\n",
    "        print(f\"  Skipping year {year} - missing data\")\n",
    "        continue\n",
    "    \n",
    "    # Find common dates\n",
    "    common_dates = set(pr_data_dict.keys()) & set(tas_data_dict.keys())\n",
    "    print(f\"  Processing {len(common_dates)} common time steps\")\n",
    "    \n",
    "    # Check areas in extent for this year's data\n",
    "    areas_in_extent = []\n",
    "    for _, row in filtered_shp.iterrows():\n",
    "        bounds = row.geometry.bounds\n",
    "        if (bounds[0] <= data_lon_range[1] and bounds[2] >= data_lon_range[0] and\n",
    "            bounds[1] <= data_lat_range[1] and bounds[3] >= data_lat_range[0]):\n",
    "            areas_in_extent.append(row['CUR_NME'])\n",
    "    \n",
    "    if not areas_in_extent:\n",
    "        print(f\"  WARNING: No protected areas overlap with data extent for year {year}\")\n",
    "        continue\n",
    "    \n",
    "    # Process each common date\n",
    "    for date_str in sorted(common_dates):\n",
    "        if len(common_dates) > 6 and list(sorted(common_dates)).index(date_str) % 3 == 0:\n",
    "            print(f\"    Processing date: {date_str}\")\n",
    "        \n",
    "        pr_info = pr_data_dict[date_str]\n",
    "        tas_info = tas_data_dict[date_str]\n",
    "        \n",
    "        # Process each protected area\n",
    "        for _, row in filtered_shp.iterrows():\n",
    "            if row['CUR_NME'] not in areas_in_extent:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Extract precipitation data\n",
    "                pr_stats = rstats.zonal_stats(\n",
    "                    row.geometry,\n",
    "                    pr_info['data'],\n",
    "                    affine=pr_info['affine'],\n",
    "                    raster_out=True,\n",
    "                    nodata=np.nan,\n",
    "                    all_touched=True\n",
    "                )\n",
    "                \n",
    "                # Extract temperature data\n",
    "                tas_stats = rstats.zonal_stats(\n",
    "                    row.geometry,\n",
    "                    tas_info['data'],\n",
    "                    affine=tas_info['affine'],\n",
    "                    raster_out=True,\n",
    "                    nodata=np.nan,\n",
    "                    all_touched=True\n",
    "                )\n",
    "                \n",
    "                if (pr_stats and len(pr_stats) > 0 and pr_stats[0] is not None and\n",
    "                    tas_stats and len(tas_stats) > 0 and tas_stats[0] is not None):\n",
    "                    \n",
    "                    pr_stat = pr_stats[0]\n",
    "                    tas_stat = tas_stats[0]\n",
    "                    \n",
    "                    if ('mini_raster_array' in pr_stat and pr_stat['mini_raster_array'] is not None and\n",
    "                        'mini_raster_array' in tas_stat and tas_stat['mini_raster_array'] is not None):\n",
    "                        \n",
    "                        pr_arr = pr_stat['mini_raster_array']\n",
    "                        tas_arr = tas_stat['mini_raster_array']\n",
    "                        pr_affine = pr_stat['mini_raster_affine']\n",
    "                        \n",
    "                        # Get valid pixels (where both variables have data)\n",
    "                        pr_rows, pr_cols = np.where(~np.isnan(pr_arr))\n",
    "                        tas_rows, tas_cols = np.where(~np.isnan(tas_arr))\n",
    "                        \n",
    "                        # Find intersection of valid pixels\n",
    "                        pr_pixels = set(zip(pr_rows, pr_cols))\n",
    "                        tas_pixels = set(zip(tas_rows, tas_cols))\n",
    "                        valid_pixels = pr_pixels & tas_pixels\n",
    "                        \n",
    "                        if len(valid_pixels) == 0:\n",
    "                            continue\n",
    "                        \n",
    "                        for r, c in valid_pixels:\n",
    "                            try:\n",
    "                                lon, lat = rio.transform.xy(pr_affine, r, c)\n",
    "                                pr_val = pr_arr[r, c]\n",
    "                                tas_val = tas_arr[r, c]\n",
    "                                \n",
    "                                # Handle coordinate format\n",
    "                                if isinstance(lon, (list, tuple)):\n",
    "                                    lon = lon[0]\n",
    "                                if isinstance(lat, (list, tuple)):\n",
    "                                    lat = lat[0]\n",
    "\n",
    "                                # Create a unique key for the pixel based on its coordinates\n",
    "                                pixel_key = (round(lon, 4), round(lat, 4))\n",
    "                                if pixel_key not in pixel_id_map:\n",
    "                                    pixel_id_map[pixel_key] = pixel_counter\n",
    "                                    pixel_counter += 1\n",
    "\n",
    "                                pixel_id = pixel_id_map[pixel_key]\n",
    "                                \n",
    "                                # Create record with both climate variables\n",
    "                                record = {\n",
    "                                    'pixel_id': pixel_id,\n",
    "                                    'NDVI': np.nan,  # Placeholder\n",
    "                                    'Human_Modification': np.nan,  # Placeholder\n",
    "                                    'date': date_str,\n",
    "                                    'area_name': row['CUR_NME'],\n",
    "                                    'elevation': row.get('elevation', np.nan),\n",
    "                                    'T_BIOME': row.get('T_BIOME', 'NA'),\n",
    "                                    'Temperature_C': float(tas_val),\n",
    "                                    'Precipitation_mm': float(pr_val)\n",
    "                                }\n",
    "                                \n",
    "                                all_pixel_data.append(record)\n",
    "                                \n",
    "                            except Exception as e:\n",
    "                                print(f\"      Error processing pixel: {e}\")\n",
    "                                continue\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"    Error in zonal stats for {row['CUR_NME']}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"  Completed year {year}. Current total records: {len(all_pixel_data)}\")\n",
    "    gc.collect()\n",
    "\n",
    "print(f\"\\nExtraction complete. Total records: {len(all_pixel_data)}\")\n",
    "\n",
    "# Save results to CSV\n",
    "if all_pixel_data:\n",
    "    print(\"Converting to DataFrame...\")\n",
    "    pixel_df = pd.DataFrame(all_pixel_data)\n",
    "    \n",
    "    # Save full dataset\n",
    "    output_csv = f'/Users/collinsmatiza/Downloads/isimip3a/pixel_timeseries_monthly_1982_2015_mm_month_{TARGET_RESOLUTION}deg.csv'\n",
    "    print(f\"Saving data to: {output_csv}\")\n",
    "    pixel_df.to_csv(output_csv, index=False)\n",
    "    print(f\"Data saved successfully\")\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nSummary of extracted data:\")\n",
    "    print(f\"Total records: {len(pixel_df)}\")\n",
    "    print(f\"Total unique pixels: {len(pixel_df['pixel_id'].unique())}\")\n",
    "    print(f\"Date range: {pixel_df['date'].min()} to {pixel_df['date'].max()}\")\n",
    "    print(f\"Units: mm/month\")\n",
    "    print(f\"Pixel resolution: {TARGET_RESOLUTION} degrees\")\n",
    "    print(f\"Columns: {list(pixel_df.columns)}\")\n",
    "    \n",
    "    for area in target_areas:\n",
    "        area_data = pixel_df[pixel_df['area_name'] == area]\n",
    "        if len(area_data) > 0:\n",
    "            print(f\"\\n{area}:\")\n",
    "            print(f\"  Total records: {len(area_data)}\")\n",
    "            print(f\"  Unique pixels: {len(area_data['pixel_id'].unique())}\")\n",
    "            print(f\"  Pixel ID range: {area_data['pixel_id'].min()} to {area_data['pixel_id'].max()}\")\n",
    "            print(f\"  Years covered: {sorted(area_data['date'].str[:4].unique())}\")\n",
    "            print(f\"  Precipitation range: {area_data['Precipitation_mm'].min():.4f} to {area_data['Precipitation_mm'].max():.4f} mm/month\")\n",
    "        else:\n",
    "            print(f\"\\n{area}: No data found (likely outside data extent)\")\n",
    "    \n",
    "    # Save summary statistics\n",
    "    if len(pixel_df) > 0 and 'date' in pixel_df.columns:\n",
    "        print(\"Creating yearly summary...\")\n",
    "        pixel_df['year'] = pixel_df['date'].str[:4]\n",
    "        yearly_summary = pixel_df.groupby(['area_name', 'year'])['Precipitation_mm'].agg([\n",
    "            'count', 'mean', 'min', 'max', 'std'\n",
    "        ]).reset_index()\n",
    "        yearly_summary['units'] = 'mm/month'\n",
    "        yearly_summary['pixel_resolution_deg'] = TARGET_RESOLUTION\n",
    "        \n",
    "        summary_csv = f'/Users/collinsmatiza/Downloads/isimip3a/yearly_summary_1982_2015_mm_month_{TARGET_RESOLUTION}deg.csv'\n",
    "        yearly_summary.to_csv(summary_csv, index=False)\n",
    "        print(f\"Yearly summary saved to: {summary_csv}\")\n",
    "else:\n",
    "    print(\"No data extracted - likely no overlap between protected areas and data extent\")\n",
    "\n",
    "print(\"Processing complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
